
% Default to the notebook output style

    


% Inherit from the specified cell style.




    
\documentclass[11pt]{article}

    
    
    \usepackage[T1]{fontenc}
    % Nicer default font (+ math font) than Computer Modern for most use cases
    \usepackage{mathpazo}

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % We will generate all images so they have a width \maxwidth. This means
    % that they will get their normal width if they fit onto the page, but
    % are scaled down if they would overflow the margins.
    \makeatletter
    \def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth
    \else\Gin@nat@width\fi}
    \makeatother
    \let\Oldincludegraphics\includegraphics
    % Set max figure width to be 80% of text width, for now hardcoded.
    \renewcommand{\includegraphics}[1]{\Oldincludegraphics[width=.8\maxwidth]{#1}}
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionLabelFormat{nolabel}{}
    \captionsetup{labelformat=nolabel}

    \usepackage{adjustbox} % Used to constrain images to a maximum size 
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro
    \usepackage[mathletters]{ucs} % Extended unicode (utf-8) support
    \usepackage[utf8x]{inputenc} % Allow utf-8 characters in the tex document
    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics 
                         % to support a larger range 
    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    

    
    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}
    
    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    
    
    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatability definitions
    \def\gt{>}
    \def\lt{<}
    % Document parameters
    \title{03\_operators}
    
    
    

    % Pygments definitions
    
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\expandafter\def\csname PY@tok@w\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PY@tok@c\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.74,0.48,0.00}{##1}}}
\expandafter\def\csname PY@tok@k\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\expandafter\def\csname PY@tok@o\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ow\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@nb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@ne\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.82,0.25,0.23}{##1}}}
\expandafter\def\csname PY@tok@nv\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@no\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@nl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@ni\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.60,0.60,0.60}{##1}}}
\expandafter\def\csname PY@tok@na\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.49,0.56,0.16}{##1}}}
\expandafter\def\csname PY@tok@nt\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@s\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sd\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@si\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@se\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.13}{##1}}}
\expandafter\def\csname PY@tok@sr\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@ss\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sx\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@m\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@gh\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gu\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@gi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@gr\endcsname{\def\PY@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@ge\endcsname{\let\PY@it=\textit}
\expandafter\def\csname PY@tok@gs\endcsname{\let\PY@bf=\textbf}
\expandafter\def\csname PY@tok@gp\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@go\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.53,0.53}{##1}}}
\expandafter\def\csname PY@tok@gt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PY@tok@err\endcsname{\def\PY@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PY@tok@kc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kd\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kr\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@bp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@fm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@vc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vg\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sa\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@dl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s2\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s1\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@mb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@il\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mo\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ch\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cm\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cpf\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@c1\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cs\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % Exact colors from NB
    \definecolor{incolor}{rgb}{0.0, 0.0, 0.5}
    \definecolor{outcolor}{rgb}{0.545, 0.0, 0.0}



    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy 
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

    \begin{document}
    
    
    \maketitle
    
    

    
    \subsection{Notas de aula: Mecânica Quântica, Autor: Jonas Maziero,
Departamento de Física,
UFSM}\label{notas-de-aula-mecuxe2nica-quuxe2ntica-autor-jonas-maziero-departamento-de-fuxedsica-ufsm}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}2}]:} \PY{o}{\PYZpc{}}\PY{k}{run} init.ipynb
\end{Verbatim}


    \section{Operadores lineares}\label{operadores-lineares}

    Um \emph{operador linear} é qualquer função \(A:V\rightarrow W\) (leva
vetores do espaço vetorial \(V\) para o espaço vetorial \(W\)) que é
linear no seu domínio. Ou seja, para \(c_{j}\in\mathbb{F}\) e
\(|v_{j}\rangle\in V\) devemos ter

\begin{equation}
A(\sum_{j}c_{j}|v_{j}\rangle) = \sum_{j}c_{j}A(|v_{j}\rangle).
\end{equation}

Além disso, exigiremos que se \(A,B:V\rightarrow W\) são operadores
lineares, então \(\forall|v\rangle\in V\) e
\(\alpha,\beta\in\mathbb{F}\) devemos ter

\begin{equation}
(\alpha A+\beta B)(|v\rangle) = \alpha A(|v\rangle)+\beta B(|v\rangle).
\end{equation}

\emph{OBS:} Quando \(A:V\rightarrow V\) dizemos que \(A\) está definido
em \(V\). \emph{OBS:} Dois operadores lineares particularmente
importantes são o operdor identidade, definido por

\begin{equation}
\mathbb{I}_{V}|v\rangle=|v\rangle\text{, }\forall |v\rangle\in V,
\end{equation}

e o operador nulo, definido por

\begin{equation}
\mathbb{O}_{V}|v\rangle=|\oslash\rangle\text{, }\forall |v\rangle\in V.
\end{equation}

\textbf{OBS:} Como qualquer vetor \(|v\rangle\in V\) pode ser escrito
como uma combinação linear dos vetores de uma certa base
\(\{|w_{j}\rangle\}_{j=1}^{\dim V}\), i.e.,
\(|v\rangle=\sum_{j}c_{j}|w_{j}\rangle\) com \(c_{j}\in\mathbb{F}\), se
sabemos como um certo operador linear atua em uma base qualquer de
\(V\), sabemos como ele atua em todos os vetores de \(V\) pois

\begin{equation}
A(|v\rangle) = A\left(\sum_{j}c_{j}|w_{j}\rangle\right)=\sum_{j}c_{j}A(|w_{j}\rangle). 
\end{equation}

    \subsubsection{Matrizes são operadores
lineares}\label{matrizes-suxe3o-operadores-lineares}

Considere matrizes retangulares \(A\in\mathbb{C}^{m\text{x}n}\). Não é
difícil ver que para \(|v\rangle\in\mathbb{C}^{n}\) e
\(|v'\rangle\in\mathbb{C}^{m}\) teremos

\begin{align}
& \begin{bmatrix} |v'\rangle_{1} \\ |v'\rangle_{2} \\ \vdots \\ |v'\rangle_{m} \end{bmatrix} = \begin{bmatrix} A_{1,1} & A_{1,2} & \cdots & A_{1,n} \\ A_{2,1} & A_{2,2} & \cdots & A_{2,n} \\ \vdots & \vdots & \vdots & \vdots \\ A_{m,1} & A_{m,2} & \cdots & A_{m,n} \end{bmatrix} \begin{bmatrix} |v\rangle_{1} \\ |v\rangle_{2} \\ \vdots \\ |v\rangle_{n} \end{bmatrix} \Rightarrow |v'\rangle_{j} = \sum_{k=1}^{n}A_{j,k}|v\rangle_{k}\text{ para }j=1,\cdots,m \\
& \text{ou, equivalentemente, } |v'\rangle=A|v\rangle.
\end{align}

Ou seja, \(A:\mathbb{C}^{n}\rightarrow\mathbb{C}^{m}\). Para verificar
linearidade consideremos \(|w\rangle,|w_{j}\rangle\in\mathbb{C}^{n}\),
\(c_{j}\in\mathbb{C}\) e \(|w\rangle=\sum_{j}c_{j}|w_{j}\rangle\) e
olhemos para

\begin{equation}
\left(A\sum_{j}c_{j}|w_{j}\rangle\right)_{k} = (A|w\rangle)_{k} = \sum_{l}A_{k,l}|w\rangle_{l} = \sum_{l}A_{k,l}\sum_{j}c_{j}|w_{j}\rangle_{l} = \sum_{j}c_{j}\sum_{l}A_{k,l}|w_{j}\rangle_{l} = \sum_{j}c_{j}(A|w_{j}\rangle)_{k},
\end{equation}

o que implica que
\(A\left(\sum_{j}c_{j}|w_{j}\rangle\right)=\sum_{j}c_{j}A(|w_{j}\rangle)\)
e portanto que matrizes são operadores lineares.

Ademais, como \((\alpha A+\beta B)_{j,k}=\alpha A_{j,k}+\beta B_{j,k}\),
teremos que

\begin{align}
((\alpha A+\beta B)(|v\rangle))_{j} &= \sum_{k}(\alpha A+\beta B)_{j,k}|v\rangle_{k} = \sum_{k}(\alpha A_{j,k}+\beta B_{j,k})|v\rangle_{k} = \alpha\sum_{k}A_{j,k}|v\rangle_{k} + \beta\sum_{k}B_{j,k}|v\rangle_{k} \\ 
& = \alpha(A|v\rangle)_{j}+ \beta(B|v\rangle)_{j}
\end{align}

e portanto
\((\alpha A+\beta B)(|v\rangle)= \alpha A(|v\rangle) + \beta B(|v\rangle)\).

Os operadores identidade e nulo são identificados, respectivamente, com

\begin{equation}
\mathbb{I}=\begin{bmatrix} 1 & 0 & \cdots & 0 \\ 0 & 1 & \cdots & 0 \\ \vdots & \vdots & \vdots & \vdots \\ 0 & 0 & \cdots & 1 \end{bmatrix} \text{ e } \mathbb{0}=\begin{bmatrix} 0 & 0 & \cdots & 0 \\ 0 & 0 & \cdots & 0 \\ \vdots & \vdots & \vdots & \vdots \\ 0 & 0 & \cdots & 0 \end{bmatrix}.
\end{equation}

    \subsubsection{Representação matricial de operadores
lineares}\label{representauxe7uxe3o-matricial-de-operadores-lineares}

Consideremos \(A:V\rightarrow W\) e duas bases
\(\{|v_{j}\rangle\}_{j=1}^{\dim V}\) de \(V\) e
\(\{|w_{k}\rangle\}_{k=1}^{\dim W}\) de \(W\). Sabemos que \(A\) atuando
em um vetor de \(V\) retorna um vetor de \(W\), i.e.,
\(A(|v_{j}\rangle)\in W\), que por sua vez pode ser escrito como uma
combinação linear dos vetores de qualquer uma das bases de \(W\). Então
podemos escrever

\begin{equation}
A(|v_{j}\rangle) = \sum_{k=1}^{\dim W}A_{k,j}|w_{k}\rangle, \text{ para } j=1,\cdots,\dim V,
\end{equation}

onde os coeficientes da combinação linear, \(A_{k,j}\in\mathbb{F}\),
fornecem a representação matricial de \(A\):

\begin{equation}
A \doteq \begin{bmatrix} A_{1,1} & A_{1,2} & \cdots & A_{1,\dim V} \\ 
A_{2,1} & A_{2,2} & \cdots & A_{2,\dim V} \\ 
\vdots & \vdots & \vdots & \vdots 
\\ A_{\dim W,1} & A_{\dim W,2} & \cdots & A_{\dim W,\dim V} \end{bmatrix}.
\end{equation}

\emph{OBS:} Note que fizemos o mesmo para vetores. Ou seja, se na base
\(\{|w_{k}\rangle\}_{k=1}^{\dim W}\) o vetor \(|w\rangle\in W\) é
escrito como \(|w\rangle=\sum_{j=1}^{\dim W}c_{j}|w_{j}\rangle\) dizemos
que os coeficientes \(c_{j}\in\mathbb{F}\) fornecem a representação
matricial de \(|w\rangle\) naquela base:

\begin{equation}
|w\rangle \doteq \begin{bmatrix} c_{1} \\ c_{2} \\ \vdots \\ c_{\dim W} \end{bmatrix}.
\end{equation}

\paragraph{Exemplo}\label{exemplo}

Considere a base \(\{|e_{1}\rangle,|e_{2}\rangle\}\) e
\(A:V\rightarrow V\) que atua como segue:

\begin{equation}
A(|e_{1}\rangle):=|e_{2}\rangle \text{ e } A(|e_{2}\rangle):=|e_{1}\rangle.
\end{equation}

Teremos assim que

\begin{equation}
A(|e_{1}\rangle)=\sum_{k=1}^{2}A_{k,1}|e_{k}\rangle = A_{1,1}|e_{1}\rangle+ A_{2,1}|e_{2}\rangle \text{ e } A(|e_{2}\rangle)=\sum_{k=1}^{2}A_{k,2}|e_{k}\rangle = A_{1,2}|e_{1}\rangle+ A_{2,2}|e_{k}\rangle.
\end{equation}

Então, comparando a definição com estas últimas relações teremos

\begin{equation}
A \doteq \begin{bmatrix} A_{1,1} & A_{1,2} \\ A_{2,1} & A_{2,2} \end{bmatrix} = \begin{bmatrix} 0 & 1 \\ 1 & 0 \end{bmatrix}.
\end{equation}

\textbf{Exercício:} Considere a base \(\{|e_{1}\rangle,|e_{2}\rangle\}\)
e \(B:V\rightarrow V\) que atua como segue:
\(B(|e_{1}\rangle)=(|e_{1}\rangle+|e_{2}\rangle)/\sqrt{2}\) e
\(B(|e_{2}\rangle)=(|e_{1}\rangle-|e_{2}\rangle)/\sqrt{2}\). Forneça a
representação matricial de \(B\) nesse caso.

\textbf{Exercício:} Forneça a representação matricial dos vetores da
base \(\{|e_{1}\rangle,|e_{2}\rangle\}\) na base base
\(\{|e_{1}\rangle,|e_{2}\rangle\}\).

    \subsubsection{Composição de operadores
lineares}\label{composiuxe7uxe3o-de-operadores-lineares}

Consideremos operadores lineares \(A:V\rightarrow W\) e
\(B:W\rightarrow X\) e as seguintes bases para estes espaços vetoriais:
\(\{|v_{j}\rangle\}_{j=1}^{\dim V}\in V\),
\(\{|w_{j}\rangle\}_{j=1}^{\dim W}\in W\) e
\(\{|x_{j}\rangle\}_{j=1}^{\dim X}\in X\). Quando atuamos primeiro \(A\)
e depois \(B\) (notação: \(B\circ A\)) veremos que isso é equivalente a
aplicar um único operador linear \(C:V\rightarrow X\), cuja
representação matricial pode ser obtida daquelas de \(A\) e de \(B\).
Explicitando, para \(j=1,\cdots,\dim V\) temos

\begin{equation}
A(|v_{j}\rangle) = \sum_{k=1}^{\dim W} A_{k,j}|w_{k}\rangle.
\end{equation}

Seguindo,

\begin{align}
(B\circ A)(|v_{j}\rangle) & \equiv B(A(|v_{j}\rangle)) = B(\sum_{k=1}^{\dim W} A_{k,j}|w_{k}\rangle) = \sum_{k=1}^{\dim W} A_{k,j}B(|w_{k}\rangle) = \sum_{k=1}^{\dim W} A_{k,j}\sum_{l=1}^{\dim X}B_{l,k}|x_{l}\rangle \\
& = \sum_{l=1}^{\dim X}\left(\sum_{k=1}^{\dim W} B_{l,k}A_{k,j}\right)|x_{l}\rangle =: \sum_{l=1}^{\dim X}C_{l,j}|x_{l}\rangle =: C(|v_{j}\rangle).
\end{align}

\textbf{Exercício:} Forneça a representação matricial para
\(C=B\circ A\), com \(A\) e \(B\) sendo os operadores definidos no
último exemplo e exercício, respectivamente.

    \subsection{Autovalores e autovetores}\label{autovalores-e-autovetores}

Se a ação de um operador linear \(A:V\rightarrow V\) não muda a
"direção" de um vetor \(|a\rangle\in V\), i.e., se

\begin{equation}
A|a\rangle\propto |a\rangle =: \alpha|a\rangle,
\end{equation}

dizemos que \(|a\rangle\) é um autovetor de \(A\) e \(\alpha\) é o
autovalor \(A\) correpondente ao autovetor \(|a\rangle\). Note que
\(\alpha\) nos indica quanto o tamanho do autovetor muda e se esse muda
ou não de sentido sob a ação de \(A\).

\textbf{Exercício:} Verifique que
\(||\alpha*|a\rangle||=|\alpha|*||a||\).

\paragraph{Exemplo}\label{exemplo}

Considere o operador definido por
\(A(|e_{1}\rangle)=|e_{2}\rangle \text{ e } A(|e_{2}\rangle)=|e_{1}\rangle\).
Notamos que para \(|a_{\pm}\rangle=|e_{1}\rangle\pm|e_{2}\rangle\)
teremos

\begin{equation}
A|a_{\pm}\rangle = A(|e_{1}\rangle\pm|e_{2}\rangle) = A|e_{1}\rangle\pm A|e_{2}\rangle = |e_{2}\rangle\pm |e_{1}\rangle = \pm(|e_{1}\rangle \pm |e_{2}\rangle) = (\pm1)|a_{\pm}\rangle = \alpha_{\pm}|a_{\pm}\rangle.
\end{equation}

\subsubsection{Equação
característica}\label{equauxe7uxe3o-caracteruxedstica}

Vamos reescrever a equação de autovalores e autovetores acima da
seguinte forma:

\begin{equation}
A|a\rangle=\alpha\mathbb{I}|a\rangle \hspace{0.3cm} \therefore(A-\alpha\mathbb{I})|a\rangle=|\oslash\rangle.
\end{equation}

Note que se \(A-\alpha\mathbb{I}\) possuir inversa, então
\(|a\rangle=|\oslash\rangle\). Para ter uma \emph{solução não trivial}
devemos ter a chamada equação secular ou equação característica:

\begin{equation}
\det(A-\alpha\mathbb{I})=\det\begin{bmatrix} A_{1,1}-\alpha & A_{1,2} & \cdots & A_{1,\dim V} \\ 
A_{2,1} & A_{2,2}-\alpha & \cdots & A_{2,\dim V} \\ 
\vdots & \vdots & \vdots & \vdots 
\\ A_{\dim V,1} & A_{\dim V,2} & \cdots & A_{\dim V,\dim V}-\alpha \end{bmatrix}=0.
\end{equation}

Para um espaço vetorial de dimenção \(n\), essa equação resulta em um
polinômio de ordem \(n\),

\begin{equation}
c_{n}\alpha^{n}+c_{n-1}\alpha^{n-1}+\cdots+c_{2}\alpha^{2}+c_{1}\alpha+c_{0}=0,
\end{equation}

que possui \(n\) raízes complexas, que são os autovalores de \(A\).

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}11}]:} \PY{n}{a}\PY{p}{,}\PY{n}{b}\PY{p}{,}\PY{n}{c}\PY{p}{,}\PY{n}{d} \PY{o}{=} \PY{n}{symbols}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{a b c d}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n}{A} \PY{o}{=} \PY{n}{Matrix}\PY{p}{(}\PY{p}{[}\PY{p}{[}\PY{n}{a}\PY{p}{,}\PY{n}{b}\PY{p}{]}\PY{p}{,}\PY{p}{[}\PY{n}{c}\PY{p}{,}\PY{n}{d}\PY{p}{]}\PY{p}{]}\PY{p}{)}
         \PY{c+c1}{\PYZsh{}A = Matrix([[0,\PYZhy{}1j],[1j,0]])}
         \PY{c+c1}{\PYZsh{}A}
         \PY{n}{A}\PY{o}{.}\PY{n}{eigenvects}\PY{p}{(}\PY{p}{)}
         \PY{c+c1}{\PYZsh{} Na lista abaixo aparecem (autovalor, multiplicidade, autovetor)}
\end{Verbatim}

\texttt{\color{outcolor}Out[{\color{outcolor}11}]:}
    
    $$\left [ \left ( \frac{a}{2} + \frac{d}{2} - \frac{1}{2} \sqrt{a^{2} - 2 a d + 4 b c + d^{2}}, \quad 1, \quad \left [ \left[\begin{matrix}- \frac{b}{\frac{a}{2} - \frac{d}{2} + \frac{1}{2} \sqrt{a^{2} - 2 a d + 4 b c + d^{2}}}\\1\end{matrix}\right]\right ]\right ), \quad \left ( \frac{a}{2} + \frac{d}{2} + \frac{1}{2} \sqrt{a^{2} - 2 a d + 4 b c + d^{2}}, \quad 1, \quad \left [ \left[\begin{matrix}- \frac{b}{\frac{a}{2} - \frac{d}{2} - \frac{1}{2} \sqrt{a^{2} - 2 a d + 4 b c + d^{2}}}\\1\end{matrix}\right]\right ]\right )\right ]$$

    

    \textbf{Exemplo:} Vamos calcular os autovalores e autovetores da matriz
\(\sigma_{y}=\begin{bmatrix}0&1\\1&0\end{bmatrix}\). Para os
autovalores:

\begin{equation}
\det(\sigma_{y}-\alpha\mathbb{I}_{2}) = \det\begin{bmatrix}-\alpha&1\\1&-\alpha\end{bmatrix}=\alpha^{2}-1=0\Rightarrow \alpha=\pm 1.
\end{equation}

Para os autovetores, se \(\alpha=1\) teremos

\begin{equation}
\begin{bmatrix}0&1\\1&0\end{bmatrix}\begin{bmatrix}a\\b\end{bmatrix}=(1)\begin{bmatrix}a\\b\end{bmatrix}\Rightarrow b=a=1\Rightarrow |\alpha=1\rangle = \begin{bmatrix}1\\1\end{bmatrix}.
\end{equation}

Para \(\alpha=-1\) teremos

\begin{equation}
\begin{bmatrix}0&1\\1&0\end{bmatrix}\begin{bmatrix}a\\b\end{bmatrix}=(-1)\begin{bmatrix}a\\b\end{bmatrix}\Rightarrow b=-a=1\Rightarrow |\alpha=1\rangle = \begin{bmatrix}1\\-1\end{bmatrix}.
\end{equation}

\textbf{Exercício:} Calcule os autovalores e autovetores da matriz
\(\begin{bmatrix}1 & 1 \\ 1 & -1 \end{bmatrix}\).

    \subsubsection{Adjunto de um operador
linear}\label{adjunto-de-um-operador-linear}

Seja \(V\) um espaço de Hilbert. Então, por definição, para qualquer
operador linear \(A:V\rightarrow V\) existe o operador adjunto a \(A\),
denotado por \(A^{\dagger}:V\rightarrow V\), tal que

\begin{equation}
(|v\rangle,A|w\rangle) = (A^{\dagger}|v\rangle,|w\rangle)\text{, }\forall|v\rangle,|w\rangle\in V.
\end{equation}

Por conveniência, aqui usamos \((|a\rangle,|b\rangle)\) para o produto
interno de \(|a\rangle\) e \(|b\rangle\).

Vamos verificar que a representação matricial de \(A^{\dagger}\) é dada
pela transposta conjugada da representação matricial de \(A\). Para isso
vamos considerar uma base ortonormal
\(\{|b_{j}\rangle\}_{j=1}^{\dim V}\in V\) e escrever
\(|v\rangle = \sum_{j=1}^{\dim V}v_{j}|b_{j}\rangle\) e
\(|w\rangle = \sum_{j=1}^{\dim V}w_{j}|b_{j}\rangle\). Assim

\begin{align}
(|v\rangle,A|w\rangle) & = (\sum_{j=1}^{\dim V}v_{j}|b_{j}\rangle,A\sum_{k=1}^{\dim V}w_{k}|b_{k}\rangle) = (\sum_{j=1}^{\dim V}v_{j}|b_{j}\rangle,\sum_{k=1}^{\dim V}w_{k}A|b_{k}\rangle) \\ 
& = \sum_{j,k=1}^{\dim V}v^{*}_{j}w_{k}(|b_{j}\rangle,\sum_{l=1}^{\dim V}A_{l,k}|b_{l}\rangle) = \sum_{j,k,l=1}^{\dim V}v^{*}_{j}w_{k}A_{l,k}(|b_{j}\rangle,|b_{l}\rangle) = \sum_{j,k,l=1}^{\dim V}v^{*}_{j}w_{k}A_{l,k}\delta_{j,l} \\ 
& = \sum_{j,k=1}^{\dim V}v^{*}_{j}w_{k}A_{j,k}
\end{align}

e

\begin{align}
(A^{\dagger}|v\rangle,|w\rangle) & = (A^{\dagger}\sum_{j=1}^{\dim V}v_{j}|b_{j}\rangle,\sum_{k=1}^{\dim V}w_{k}|b_{k}\rangle) = (\sum_{j=1}^{\dim V}v_{j}A^{\dagger}|b_{j}\rangle,\sum_{k=1}^{\dim V}w_{k}|b_{k}\rangle) \\ 
& = \sum_{j,k=1}^{\dim V}v^{*}_{j}w_{k}(\sum_{l=1}^{\dim V}(A^{\dagger})_{l,j}|b_{l}\rangle,|b_{k}\rangle)  = \sum_{j,k,l=1}^{\dim V}v^{*}_{j}w_{k}(A^{\dagger}_{l,j})^{*}(|b_{l}\rangle,|b_{k}\rangle) = \sum_{j,k,l=1}^{\dim V}v^{*}_{j}w_{k}(A^{\dagger}_{l,j})^{*}\delta_{l,k} \\ 
& = \sum_{j,k=1}^{\dim V}v^{*}_{j}w_{k}(A^{\dagger}_{k,j})^{*}.
\end{align}

Ou seja,

\begin{equation}
(|v\rangle,A|w\rangle) = (A^{\dagger}|v\rangle,|w\rangle)\Rightarrow (A^{\dagger})_{j,k} = A_{k,j}^{*}
\end{equation}

para a representação matricial desses operadores em uma base ortonormal.

    \emph{OBS:} Nas notas sobre determinantes, vocês verificaram que os
autovelores de \(A^{\dagger}\) são iguais ao complexo conjugado dos
autovalores de \(A\). Vamos usar este resultado para verificar que
\(A^{\dagger}\) e \(A\) compartilham autovetores. Para
\(A|a\rangle=\alpha|a\rangle\) teremos

\begin{equation}
(A^{\dagger}|a\rangle,|a\rangle) = (|a\rangle,A|a\rangle) = (|a\rangle,\alpha|a\rangle) = \alpha(|a\rangle,|a\rangle) = (\alpha^{*}|a\rangle,|a\rangle),
\end{equation}

que nos mostra que \(A^{\dagger}|a\rangle=\alpha^{*}|a\rangle\).

\textbf{Exercício:} Verique que \((A^{\dagger})^{\dagger}=A\).

\textbf{Exercício:} Verifique que se \(\alpha\) é um escalar então
\((\alpha A)^{\dagger}=\alpha^{*}A^{\dagger}\).

\textbf{Exercício:} Verifique que para
\(A,B:\mathcal{H}\rightarrow\mathcal{H}\), temos
\((A\circ B)^{\dagger} = B^{\dagger}\circ A^{\dagger}\).

    \subsection{Projetores}\label{projetores}

Seja \(\{|w_{j}\rangle\}_{j=1}^{\dim W}\) uma base ortonormal de \(W\).
O \emph{projetor no subespaço \(W\)} é um operador
\(P_{W}:V\rightarrow W\) definido por

\begin{equation}
P_{W}(|v\rangle) := \sum_{j=1}^{\dim W}\langle w_{j}|v\rangle|w_{j}\rangle,
\end{equation}

com \(|v\rangle\in V\).

\textbf{Exemplo:} Para \(\mathbb{C}^{n}\) temos
\(\langle v|w\rangle = |v\rangle^{\dagger}|w\rangle\). Nesse caso usamos

\begin{equation}
|v\rangle^{\dagger} = \langle v|
\end{equation}

para qualquer vetor. Assim, teremos
\(P_{W}(|v\rangle) = \sum_{j=1}^{\dim W}|w_{j}\rangle|w_{j}\rangle^{\dagger}|v\rangle = (\sum_{j=1}^{\dim W}|w_{j}\rangle\langle w_{j}|)|v\rangle\).
Por conseguinte, para este espaço vetorial, teremos

\begin{equation}
P_{W} = \sum_{j=1}^{\dim W}|w_{j}\rangle\langle w_{j}|.
\end{equation}

\textbf{Exercício:} Escreva explicitamento o projetor em um subespaço do
espaço de Hilbert
\(\mathcal{H}=\left(\mathbb{C}^{n\mathrm{x}n},\langle A|B\rangle_{hs}=Tr(A^{\dagger}B)\right)\).

    \emph{OBS:} \(P_{W}\) atua como \(\mathbb{I}_{W}\) nos vetores de \(W\).
Consideremos um vetor qualquer \(|w\rangle\in W\) decomposto na base
ortonormal \(\{|w_{j}\rangle\}_{j=1}^{\dim W}\) como (veja as notas
sobre vetores):
\(|w\rangle=\sum_{j=1}^{\dim W}\langle w_{j}|w\rangle|w_{j}\rangle\). É
facil ver assim que

\begin{equation}
P_{W}(|w\rangle) := \sum_{j=1}^{\dim W}\langle w_{j}|v\rangle|w_{j}\rangle = |w\rangle = \mathbb{I}_{W}(|w\rangle).
\end{equation}

Sempre que \(P_{W}= \mathbb{I}_{W}\) dizemos que a base usada para
definir o projetor é uma \emph{base completa}.

    \textbf{Verificação:} \(P_{W}:V\rightarrow W\). Consideremos uma base
ortonormal para o espaço vetorial \(V\supseteq W\):
\(\{\{|w_{j}\rangle\}_{j=1}^{\dim W},\{|w^{\perp}_{k}\rangle\}_{k=\dim W+1}^{\dim V}\}\).
Assim, para um vetor qualquer \(|v\rangle\in V\) teremos

\begin{equation}
|v\rangle = \sum_{j=1}^{\dim W}\langle w_{j}|v\rangle|w_{j}\rangle + \sum_{k=\dim W+1}^{\dim V}\langle w^{\perp}_{k}|v\rangle|w^{\perp}_{k}\rangle.
\end{equation}

Então

\begin{align}
P_{W}(|v\rangle) & = \sum_{l=1}^{\dim W}\langle w_{l}|v\rangle|w_{l}\rangle = \sum_{l=1}^{\dim W}\sum_{j=1}^{\dim W}\langle w_{j}|v\rangle\langle w_{l}|w_{j}\rangle|w_{l}\rangle + \sum_{l=1}^{\dim W}\sum_{k=\dim W+1}^{\dim V}\langle w^{\perp}_{k}|v\rangle\langle w_{l}|w^{\perp}_{k}\rangle|w_{l}\rangle \\
& = \sum_{l=1}^{\dim W}\sum_{j=1}^{\dim W}\langle w_{j}|v\rangle\delta_{l,j}|w_{l}\rangle + \sum_{l=1}^{\dim W}\sum_{k=\dim W+1}^{\dim V}\langle w^{\perp}_{k}|v\rangle 0|w_{l}\rangle = \sum_{l=1}^{\dim W}\langle w_{l}|v\rangle|w_{l}\rangle \in W.
\end{align}

    \textbf{Exercício:} Verifique que \(P_{W}\circ P_{W}=P_{W}\).
\textbf{Exercício:} Verifique que um projetor possui somente dois
autovalores, 0 ou 1. Discorra sobre quais são os "autovetores"
correspondentes. \textbf{Exercício:} Verifique que se
\(P_{W}(|v\rangle) = \sum_{l=1}^{\dim W}\langle w_{l}|v\rangle|w_{l}\rangle\)
e
\(P_{X}(|v\rangle) = \sum_{l=1}^{\dim X}\langle x_{l}|v\rangle|x_{l}\rangle\)
com \(\langle x_{j}|w_{k}\rangle=0\text{ } \forall j,k\), então

\begin{equation}
P_{W}\circ P_{X} = P_{X}\circ P_{W} = \mathbb{O}_{V}.
\end{equation}

\subsubsection{Adjunto de projetores}\label{adjunto-de-projetores}

Vamos verificar que o operador adjunto de um projetor é ele mesmo.
Considera \(\forall|a\rangle,|b\rangle\in\mathcal{H}\)

\begin{align}
& (P_{W}^{\dagger}|a\rangle,|b\rangle)=(|a\rangle,P_{w}(|b\rangle)) = (|a\rangle,\sum_{j}\langle w_{j}|b\rangle|w_{j}\rangle)  = \sum_{j}\langle w_{j}|b\rangle(|a\rangle,|w_{j}\rangle) = \sum_{j}\langle w_{j}|b\rangle\langle w_{j}|a\rangle^{*} \\
& = \sum_{j}\langle w_{j}|a\rangle^{*}(|w_{j}\rangle,|b\rangle) = (\sum_{j}\langle w_{j}|a\rangle|w_{j}\rangle,|b\rangle) = (P_{W}|a\rangle,|b\rangle).
\end{align}

\textbf{Exercício:} Verifique essa propriedade explicitamente
considerando os projetores de \(\mathbb{C}^{n}\).

\subsubsection{Complemento ortonormal}\label{complemento-ortonormal}

O complemento ortonormal de um projetor \(P_{W}\) no subespaço
\(W\subseteq V\) é definido como o projetor \(P_{W^{\perp}}\) tal que

\begin{equation}
P_{W}+P_{W^{\perp}}=\mathbb{I}_{V}.
\end{equation}

Para esses projetores, teremos

\begin{align}
P_{W}\circ P_{W^{\perp}}(|v\rangle) & = P_{W}\circ(\mathbb{I}_{V}-P_{W})(|v\rangle) = P_{W}\circ\mathbb{I}_{V}(|v\rangle)-P_{W}\circ P_{W}(|v\rangle) = P_{W}(|v\rangle)-P_{W}(|v\rangle) \\ 
& = \mathbb{O}_{V}(|v\rangle).
\end{align}

\textbf{Exercício:} Para \(\mathbb{C}^{3}\), considere o projetor
\(P_{1}=|1\rangle\langle 1|\) com
\(|1\rangle=\begin{bmatrix} 1 & 0 & 0 \end{bmatrix}^{T}\). Forneça dois
complementos ortonormais para \(P_{1}\)?

    \section{Operadores normais}\label{operadores-normais}

Um operador \(A\) definido no espaço de Hilbert \(\mathcal{H}\) é dito
normal se

\begin{equation}
A\circ A^{\dagger} = A^{\dagger}\circ A.
\end{equation}

\section{Teorema (decomposição
espectral)}\label{teorema-decomposiuxe7uxe3o-espectral}

Existe uma base ortonormal de \(\mathcal{H}\) constituída por
autovetores do operador linear \(A:\mathcal{H}\rightarrow\mathcal{H}\)
se e somente se este for normal.

\subsection{Prova}\label{prova}

Vamos começar assumindo a existência de uma base ortonormal
\(\{|a\rangle\}\in\mathcal{H}\) de autovetores de \(A\), i.e.,
\(A|a\rangle := a|a\rangle\) (note que aqui usamos \(a\) também para os
autovalores). Consideremos o \emph{projetor unidimensional} aplicado a
um vetor qualquer \(|v\rangle\in\mathcal{H}\):

\begin{equation}
P_{a}(|v\rangle)=\langle a|v\rangle |a\rangle.
\end{equation}

Ademais, podemos escrever
\(|v\rangle=\sum_{a}\langle a|v\rangle|a\rangle\). Assim

\begin{equation}
A(|v\rangle) = A(\sum_{a}\langle a|v\rangle|a\rangle) = \sum_{a}\langle a|v\rangle A(|a\rangle) = \sum_{a}\langle a|v\rangle a(|a\rangle) = \sum_{a} a\langle a|v\rangle(|a\rangle) = \sum_{a} aP_{a}(|v\rangle).
\end{equation}

Essa é a chamada \emph{decomposição espectral}:

\begin{equation}
A = \sum_{a} aP_{a}.
\end{equation}

Notemos que como \(\forall|v\rangle\in\mathcal{H}\) podemos escrever
\(|v\rangle=\sum_{a}\langle a|v\rangle|a\rangle\), teremos que

\begin{equation}
(\sum_{a}P_{a})(|v\rangle)=\sum_{a}P_{a}(|v\rangle)=\sum_{a}\langle a|v\rangle|a\rangle =|v\rangle=\mathbb{I}_{\mathcal{H}}|v\rangle.
\end{equation}

Portanto, nesse caso,

\begin{equation}
\sum_{a}P_{a}=\mathbb{I}_{\mathcal{H}}.
\end{equation}

    \textbf{Exercício:} Assumindo que existe uma base ortonormal
\(\{|a\rangle\}\in\mathcal{H}\) tal que
\(A^{\dagger}|a\rangle := a^{*}|a\rangle\), verifique que podemos
escrever a decomposição espectral \(A^{\dagger} = \sum_{a} a^{*}P_{a}\).

Com isso podemos escrever

\begin{align}
A\circ A^{\dagger}(|v\rangle) & = (\sum_{a} aP_{a})\circ(\sum_{a'} a'^{*}P_{a'})(|v\rangle) = (\sum_{a} aP_{a})\circ(\sum_{a'} a'^{*}P_{a'}(|v\rangle)) = \sum_{a,a'} a a'^{*}P_{a}(P_{a'}(|v\rangle)) \\
& = \sum_{a,a'} a a'^{*}(P_{a}\circ P_{a'})(|v\rangle) = \sum_{a,a'} a a'^{*}(\delta_{a,a'}P_{a})(|v\rangle) = \sum_{a}|a|^{2}P_{a}(|v\rangle).
\end{align}

E

\begin{align}
A^{\dagger}\circ A(|v\rangle) & = (\sum_{a} a^{*}P_{a})\circ(\sum_{a'} a'P_{a'})(|v\rangle) = (\sum_{a} a^{*}P_{a})\circ(\sum_{a'} a'P_{a'}(|v\rangle)) = \sum_{a,a'}a^{*}a'P_{a}(P_{a'}(|v\rangle)) \\
& = \sum_{a,a'}a^{*}a'(P_{a}\circ P_{a'})(|v\rangle) = \sum_{a,a'}a^{*}a'(\delta_{a,a'}P_{a})(|v\rangle) = \sum_{a}|a|^{2}P_{a}(|v\rangle).
\end{align}

Por conseguinte,

\begin{equation}
\exists\{|a\rangle\}\mid A=\sum_{a}aP_{a}\text{ with }P_{a}P_{a'}=\delta_{a,a'}P_{a}\text{ e }\sum_{a}P_{a}=\mathbb{I}_{\mathcal{H}}\Rightarrow A\circ A^{\dagger}=A^{\dagger}\circ A.
\end{equation}

    Passemos para a segunda parte da prova, onde assumimos que \(A\) é
normal, i.e. que \(A\circ A^{\dagger}=A^{\dagger}\circ A\), e mostramos
que existe uma base ortonormal que o diagonaliza. Começamos considerando
o autovalor \(a\) de \(A\) e o projetor \(P_{a}\) no subespaço
\(\mathcal{H}_{a}\) de \(\mathcal{H}\) gerado pelos autovetores de \(A\)
correspondentes ao autovalor \(a\). Seja \(P_{a^{\perp}}\) o complemento
ortonormal de \(P_{a}\). Segue assim que

\begin{align}
A & = \mathbb{I}_{\mathcal{H}}\circ A\circ \mathbb{I}_{\mathcal{H}} = (P_{a}+P_{a^{\perp}})\circ A\circ(P_{a}+P_{a^{\perp}}) \\
& = P_{a}\circ A\circ P_{a} + P_{a}\circ A\circ P_{a^{\perp}} + P_{a^{\perp}}\circ A\circ P_{a} + P_{a^{\perp}}\circ A\circ P_{a^{\perp}}.
\end{align}

Agora, \(\forall|v\rangle\in\mathcal{H}\),

\begin{align}
(A\circ P_{a})(|v\rangle) & = A(P_{a}(|v\rangle)) = A\left(\sum_{a}\langle a|v\rangle|a\rangle\right) = \sum_{a}\langle a|v\rangle A(|a\rangle) = \sum_{a}\langle a|v\rangle a|a\rangle \\ 
& = a\sum_{a}\langle a|v\rangle|a\rangle = aP_{a}(|v\rangle).
\end{align}

\textbf{Exercício:} Verifique que \(A^{\dagger}\circ P_{a}=a^{*}P_{a}\).

Assim

\begin{align}
& P_{a}\circ A\circ P_{a} = P_{a}\circ aP_{a} = a P_{a}\circ P_{a} = aP_{a}, \\
& P_{a^{\perp}}\circ A\circ P_{a} = P_{a^{\perp}}\circ aP_{a}=aP_{a^{\perp}}\circ P_{a}=\mathbb{O}_{\mathcal{H}}.
\end{align}

Com isso teremos que

\begin{align}
(P_{a}\circ A\circ P_{a^{\perp}})^{\dagger} & = P_{a^{\perp}}^{\dagger}\circ A^{\dagger}\circ P_{a}^{\dagger} = P_{a^{\perp}}\circ A^{\dagger}\circ P_{a} = P_{a^{\perp}}\circ a^{*}P_{a} = a^{*}P_{a^{\perp}}\circ P_{a} = a^{*}\mathbb{O}_{\mathcal{H}} = \mathbb{O}_{\mathcal{H}}.
\end{align}

    Juntando esses resultados obtemos

\begin{equation}
A = aP_{a} + \mathbb{O}_{\mathcal{H}} + \mathbb{O}_{\mathcal{H}} + P_{a^{\perp}}\circ A\circ P_{a^{\perp}} = aP_{a} + P_{a^{\perp}}\circ A\circ P_{a^{\perp}}.
\end{equation}

Seguindo, verifiquemos que o operador
\(\tilde{A}:=P_{a^{\perp}}\circ A\circ P_{a^{\perp}}\) também é normal
se \(A\) é normal

\begin{align}
& (P_{a^{\perp}}\circ A\circ P_{a^{\perp}})^{\dagger}\circ(P_{a^{\perp}}\circ A\circ P_{a^{\perp}}) \\
& = P_{a^{\perp}}\circ A^{\dagger}\circ P_{a^{\perp}}\circ P_{a^{\perp}}\circ A\circ P_{a^{\perp}} = P_{a^{\perp}}\circ A^{\dagger}\circ P_{a^{\perp}}\circ A\circ P_{a^{\perp}} \\ 
& = P_{a^{\perp}}\circ A^{\dagger}\circ(\mathbb{0}_{\mathcal{H}}+ P_{a^{\perp}}\circ A\circ P_{a^{\perp}}) = P_{a^{\perp}}\circ A^{\dagger}\circ(P_{a}\circ A\circ P_{a^{\perp}} + P_{a^{\perp}}\circ A\circ P_{a^{\perp}}) \\ 
& = P_{a^{\perp}}\circ A^{\dagger}\circ((P_{a}+P_{a^{\perp}})\circ A\circ P_{a^{\perp}}) = P_{a^{\perp}}\circ A^{\dagger}\circ (\mathbb{I}_{\mathcal{H}}\circ A\circ P_{a^{\perp}}) = P_{a^{\perp}}\circ A^{\dagger}\circ A\circ P_{a^{\perp}} \\
& = P_{a^{\perp}}\circ A\circ A^{\dagger}\circ P_{a^{\perp}} = P_{a^{\perp}}\circ A\circ\mathbb{I}_{\mathcal{H}}\circ A^{\dagger}\circ P_{a^{\perp}} = P_{a^{\perp}}\circ A\circ(P_{a}+P_{a^{\perp}})\circ A^{\dagger}\circ P_{a^{\perp}} \\
& = (P_{a^{\perp}}\circ A\circ P_{a}+P_{a^{\perp}}\circ A\circ P_{a^{\perp}})\circ A^{\dagger}\circ P_{a^{\perp}} =  (\mathbb{O}_{\mathcal{H}}+P_{a^{\perp}}\circ A\circ P_{a^{\perp}})\circ A^{\dagger}\circ P_{a^{\perp}} \\
& = (P_{a^{\perp}}\circ A\circ P_{a^{\perp}})\circ(P_{a^{\perp}}\circ A^{\dagger}\circ P_{a^{\perp}})= (P_{a^{\perp}}\circ A\circ P_{a^{\perp}})\circ(P_{a^{\perp}}\circ A\circ P_{a^{\perp}})^{\dagger}.
\end{align}

Assim, se repetimos o procedimento feito inicialmete para \(A\) no caso
de \(\tilde{A}\) teremos

\begin{equation}
A = aP_{a} + \tilde{a}P_{\tilde{a}} + P_{\tilde{a}^{\perp}}\circ \tilde{A}\circ P_{\tilde{a}^{\perp}},
\end{equation}

com
\(P_{\tilde{\tilde{a}}}:=P_{\tilde{a}^{\perp}}\circ \tilde{A}\circ P_{\tilde{a}^{\perp}}\)
sendo também um operador normal. Então, se repetimos esse processo até
completarmos o espaço, i.e., até que
\(P_{a}+P_{\tilde{a}}+P_{\tilde{\tilde{a}}}+\cdots=\mathbb{I}_{\mathcal{H}}\),
teremos obtido a decomposição espectral de \(A\). Com isso completamos a
prova do teorema

\begin{equation}
A\circ A^{\dagger}=A^{\dagger}\circ A\Rightarrow \exists{\{P_{a}\}}\mid \sum_{a}P_{a}=\mathbb{I}_{\mathcal{H}}\text{ e }A=\sum_{a}aP_{a}.
\end{equation}

\textbf{Exercício:} Verifique que a matriz
\(A = \begin{bmatrix} 0 & 1 & 0 \\ 1 & 0 & 1 \\ 0 & 1 & 0 \end{bmatrix}\)
é normal e obtenha sua decomposição espectral.

    \section{Operadores Hermitianos}\label{operadores-hermitianos}

Esses são os operadores usados em Mecânica Quântica para descrever
quantidades observáveis experimentalmente. Um operador linear
\(A:\mathcal{H}\rightarrow\mathcal{H}\) é dito Hermitiano se seu adjunto
for ele próprio, i.e.,

\begin{equation}
A^{\dagger}=A.
\end{equation}

\emph{OBS:} Se um operador linear
\(A:\mathcal{H}\rightarrow\mathcal{H}\) é Hermitiano, ele também é
normal e por conseguinte possui uma decomposição espectral em uma base
ortonormal. Então, se \(A|a\rangle=a|a\rangle\) e
\(A|a'\rangle=a'|a'\rangle\) com \(a\ne a'\), devemos ter
\(\langle a|a'\rangle=0\), i.e., os autovetores correspondentes são
ortogonais.

\subsection{Teorema}\label{teorema}

Operdores Hermitianos possuem autovalores reais e seus autovetores
correspondentes a autovalores diferentes são ortogonais.

\subsubsection{Prova}\label{prova}

Considera um par qualquer de autovalores de \(A\), i.e., considera
\(A|a\rangle=a|a\rangle\) e \(A|a'\rangle=a'|a'\rangle\). Temos assim
que

\begin{align}
& (|a'\rangle,A|a\rangle) = (|a'\rangle,a|a\rangle) = a(|a'\rangle,|a\rangle) \\
& (A^{\dagger}|a'\rangle,|a\rangle)=(A|a'\rangle,|a\rangle) = (a'|a'\rangle,|a\rangle) = a'^{*}(|a'\rangle,|a\rangle).
\end{align}

Portanto

\begin{equation}
(a-a'^{*})\langle a'|a\rangle=0.
\end{equation}

Vemos assim que se \(a=a'\), como \(\langle a|a\rangle\ne 0\), devemos
ter \(a-a^{*}=0\Rightarrow \Im(a)=0\Rightarrow a\in\mathbb{R}\).
\textbackslash{}

\textbf{Exercício:} Verivique que a matriz
\(\begin{bmatrix} 0&-i\\i&0 \end{bmatrix}\) é Hermitiana. Obtenha seus
autovalores e autovetores e verifique que estes estão de acordo com o
último teorema.

\textbf{Exercício:} Operadores \textbf{anti-Hermitianos} são definidos
por \(A^{\dagger}=-A\). Mostre que esses operadores possuem uma
decomposição espectral e que os autovalores desse tipo de operador são
números imaginários puros e que seus autovetores correspondentes a
autovalores diferentes são ortogonais.

    \subsection{Comutador e
anti-comutador}\label{comutador-e-anti-comutador}

O comutador entre dois operadores lineares
\(A,B:\mathcal{H}\rightarrow\mathcal{H}\) é um operado em
\(\mathcal{H}\) deinido por

\begin{equation}
[A,B] := A\circ B - B\circ A.
\end{equation}

A importância desse operador é que se \([A,B]=\mathbb{0}\), então a
ordem com que esses operadores são aplicados não faz diferença. Caso
contrário, obteremos diferentes vetores mudando a ordem de aplicação dos
operadores.

Vemos assim que poderíamos ter definido \emph{operadores normais} como
sendo aqueles operadores que comutam com seu adjunto:

\begin{equation}
[A,A^{\dagger}] = \mathbb{0}.
\end{equation}

\textbf{Exercício:} Verifique que para
\(X,Y,Z:\mathcal{H}\rightarrow\mathcal{H}\) temos

\begin{align}
& [X,Y+Z] = [X,Y]+[X,Z], \\
& [X+Y,Z] = [X,Z]+[Y,Z], \\
& [X,Y\circ Z] = Y\circ[X,Z]+[X,Y]\circ Z, \\
& [X\circ Y,Z] = X\circ[Y,Z] + [X,Z]\circ Y.
\end{align}

A matriz identidade \(2\mathrm{x}2\) e as matrizes de Pauli são
definidas por:

\begin{equation}
\mathbb{I}_{2} \equiv \sigma_{0} := \begin{bmatrix} 1&0\\0&1 \end{bmatrix}\text{, }
\sigma_{x} \equiv \sigma_{1} := \begin{bmatrix} 0&1\\1&0 \end{bmatrix}\text{, }
\sigma_{y} \equiv \sigma_{2} := \begin{bmatrix} 0&-i\\i&0 \end{bmatrix}\text{, }
\sigma_{z} \equiv \sigma_{3} := \begin{bmatrix} 1&0\\0&-1 \end{bmatrix}\text{, }
\end{equation}

\textbf{Exercício:} Verifique que para as matrizes de Pauli teremos (use
o código abaixo para facilitar a resolução desses três exercícios)

\begin{equation}
\sigma_{j}\sigma_{k}=\delta_{j,k}\sigma_{0}+sgn(j,k,l)i\sigma_{l},  \hspace{0.2cm}  j,k=1,2,3.
\end{equation}

\textbf{Exercício:} verifique que as matrizes de Pauli satisfazem a
relação de comutação a seguir:

\begin{equation}
[\sigma_{j},\sigma_{k}]= sgn(j,k,l)2i\sigma_{l},  \hspace{0.2cm}  j,k=1,2,3.
\end{equation}

O \textbf{anti-comutador} entre dois operadores lineares
\(A,B:\mathcal{H}\rightarrow\mathcal{H}\) é o operador linear definido
como

\begin{equation}
\{A,B\} := A\circ B+B\circ A.
\end{equation}

\textbf{Exercício:} Verifique que as matrizes de Pauli anti-comutam:

\begin{equation}
\{\sigma_{j},\sigma_{k}\} := \mathbb{0}_{\mathbb{C}^{2}}, \hspace{0.2cm} \forall j\ne k \text{ e } j,k=1,2,3.
\end{equation}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}5}]:} \PY{k}{def} \PY{n+nf}{comm}\PY{p}{(}\PY{n}{A}\PY{p}{,}\PY{n}{B}\PY{p}{)}\PY{p}{:}
            \PY{k}{return} \PY{n}{A}\PY{o}{*}\PY{n}{B}\PY{o}{\PYZhy{}}\PY{n}{B}\PY{o}{*}\PY{n}{A}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}10}]:} \PY{k}{def} \PY{n+nf}{acomm}\PY{p}{(}\PY{n}{A}\PY{p}{,}\PY{n}{B}\PY{p}{)}\PY{p}{:}
             \PY{k}{return} \PY{n}{A}\PY{o}{*}\PY{n}{B}\PY{o}{+}\PY{n}{B}\PY{o}{*}\PY{n}{A}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}8}]:} \PY{k}{def} \PY{n+nf}{pauli}\PY{p}{(}\PY{n}{j}\PY{p}{)}\PY{p}{:}
            \PY{k}{if} \PY{n}{j} \PY{o}{==} \PY{l+m+mi}{0}\PY{p}{:}
                \PY{k}{return} \PY{n}{Matrix}\PY{p}{(}\PY{p}{[}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{]}\PY{p}{)}
            \PY{k}{elif} \PY{n}{j} \PY{o}{==} \PY{l+m+mi}{1}\PY{p}{:}
                \PY{k}{return} \PY{n}{Matrix}\PY{p}{(}\PY{p}{[}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{]}\PY{p}{)}
            \PY{k}{elif} \PY{n}{j} \PY{o}{==} \PY{l+m+mi}{2}\PY{p}{:}
                \PY{k}{return} \PY{n}{Matrix}\PY{p}{(}\PY{p}{[}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{n}{j}\PY{p}{]}\PY{p}{,}\PY{p}{[}\PY{l+m+mi}{1}\PY{n}{j}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{]}\PY{p}{)}
            \PY{k}{elif} \PY{n}{j} \PY{o}{==} \PY{l+m+mi}{3}\PY{p}{:}
                \PY{k}{return} \PY{n}{Matrix}\PY{p}{(}\PY{p}{[}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{]}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}14}]:} \PY{n}{comm}\PY{p}{(}\PY{n}{pauli}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{,}\PY{n}{pauli}\PY{p}{(}\PY{l+m+mi}{2}\PY{p}{)}\PY{p}{)}
\end{Verbatim}

\texttt{\color{outcolor}Out[{\color{outcolor}14}]:}
    
    $$\left[\begin{matrix}2.0 i & 0\\0 & - 2.0 i\end{matrix}\right]$$

    

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}11}]:} \PY{n}{acomm}\PY{p}{(}\PY{n}{pauli}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{,}\PY{n}{pauli}\PY{p}{(}\PY{l+m+mi}{2}\PY{p}{)}\PY{p}{)}
\end{Verbatim}

\texttt{\color{outcolor}Out[{\color{outcolor}11}]:}
    
    $$\left[\begin{matrix}0 & 0\\0 & 0\end{matrix}\right]$$

    

    \section{Teorema (diagonalização
simultânea)}\label{teorema-diagonalizauxe7uxe3o-simultuxe2nea}

Dois operadores lineares Hermitianos
\(A,B:\mathcal{H}\rightarrow\mathcal{H}\) compartilham a mesma base de
autovetores se e somente se comutarem, i.e.,

\begin{equation}
A=\sum_{j}a_{j}P_{j}\text{ e }B=\sum_{j}b_{j}P_{j}\Leftrightarrow [A,B]=\mathbb{0}_{\mathcal{H}}.
\end{equation}

\subsection{Prova}\label{prova}

Começamos assumindo que \(A\) e \(B\) são diagonalizados na mesma base
ortonormal. Assim

\begin{align}
[A,B] & = [\sum_{j}a_{j}P_{j},\sum_{k}b_{k}P_{k}] = \sum_{j,k}a_{j}b_{k}[P_{j},P_{k}] \\
& = \sum_{j,k}a_{j}b_{k}(P_{j}\circ P_{k} -P_{k}\circ P_{j}) = \sum_{j,k}a_{j}b_{k}(\delta_{j,k}P_{j} - \delta_{k,j}P_{k}) \\
& = \sum_{j}a_{j}b_{j}(P_{j} - P_{j}) = \mathbb{0}_{\mathcal{H}}.
\end{align}

Seguindo, assumimos que \(A\circ B=B\circ A\). Assim, considerando que a
decomposição espectral de \(A\) é \(A=\sum_{j}a_{j}P_{j}\), teremos

\begin{equation}
A\circ B\circ P_{j} =  B\circ A\circ P_{j} = B\circ A\circ P_{j} = B\circ a_{j}P_{j} = a_{j}B\circ P_{j}.
\end{equation}

Para que essa relação seja verdaderia, \(B\) deve levar vetores do
subespaço gerado pelos autovetores de \(A\) correspondentes ao autovalor
\(a_{j}\) em vetores desse mesmo subespaço. Mas se isso ocorre, como
\(B\) é Herminiano, deve existir uma base ortonormal desse subespaço que
é constituída por autovetores de \(B\). E isso implica que existe uma
base comum de autovetores de \(A\) e \(B\), completando assim a prova do
teorema.

Uma maneira mais fácil de entender esta última parte da prova é a
seguinte. Considera a eq. de autovalores e autovetores:
\(A|a_{j}^{(k)}\rangle=a_{j}|a_{j}^{(k)}\rangle\) com
\(k=1,\cdots,\dim\mathcal{H}_{j}\). Note que
\(\mathcal{H}_{j}\subseteq\mathcal{H}\) é o subespaço gerado pelo
autovetores de \(A\) correspondentes ao autovalor \(a_{j}\). Agora,

\begin{align}
A(B|a_{j}^{(k)}\rangle) & = (A\circ B)(|a_{j}^{(k)}\rangle) = (B\circ A)(|a_{j}^{(k)}\rangle) =B(A(|a_{j}^{(k)}\rangle)) = B(a_{j}(|a_{j}^{(k)}\rangle)) \\
& = a_{j}(B|a_{j}^{(k)}\rangle).
\end{align}

Ou seja \(B|a_{j}^{(k)}\rangle\) também é autovetor de \(A\) com
autovalor \(a_{j}\). Portanto
\(B|a_{j}^{(k)}\rangle\in \mathcal{H}_{j}\). Como \(B\) é Hermitiano,
existe uma base de \(\mathcal{H}_{j}\) que o diagonaliza, e que também
diagonaliza \(A\).

\textbf{Exercício:} Determine se \(\sigma_{x}\) e \(\sigma_{y}\)
compartilham ou não a mesma base de autovetores. Obtenha essas bases.

    \section{Operadores unitários}\label{operadores-unituxe1rios}

São utilizados para descrever a dinâmica de sistemas quânticos. Um
operador (ou matriz) \(A:\mathcal{H}\rightarrow\mathcal{H}\) é dito
unitário se

\begin{equation}
A^{\dagger}\circ A = A\circ A^{\dagger}=\mathbb{I}_{\mathcal{H}}.
\end{equation}

Ou seja, o adjunto de um operador unitário é igual a sua inversa:
\(A^{\dagger}=A^{-1}\).

\textbf{Exercício:} Verifique que se \(A\) for uma matriz unitária então
\(\det(A)=\pm1\).

Algumas outras propriedades importantes de operadores unitários são as
seguintes: 1. Operadores unitários preservam o produto interno. Ou seja,
para \(\forall|v\rangle,|w\rangle\in\mathcal{H}\) teremos

\begin{equation}
(A|v\rangle,A|w\rangle) = (A^{\dagger}\circ A|v\rangle,|w\rangle) = (\mathbb{I}_{\mathcal{H}}|v\rangle,|w\rangle) = (|v\rangle,|w\rangle).
\end{equation}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Os autovalores de um operador unitário são números complexos com
  módulo igual a 1: Considera \(A|a\rangle=a|a\rangle\). Teremos

  \begin{align}
  & (A|a\rangle,A|a\rangle) = (a|a\rangle,a|a\rangle) = a^{*}a(|a\rangle,|a\rangle) = |a|^{2}\langle a|a\rangle \\ 
  & (A^{\dagger}\circ A|a\rangle,|a\rangle) = (\mathbb{I}_{\mathcal{H}}|a\rangle,|a\rangle) = \langle a|a\rangle.
  \end{align}

  Portando \(|a|=1\) e os autovalores da matriz unitária devem ter a
  forma \(a=e^{i\theta_{a}}\). \textbf{Exercício:} Verifique que a
  matriz \(\begin{bmatrix} 0 & -i \\ i & 0 \end{bmatrix}\) é unitária,
  calcule seus autovalores e os coloque na forma polar.
\item
  O conjunto de vetores linha de uma matriz unitária
  \(A\in\mathbb{C}^{n\text{x}n}\) é um conjunto ortonormal:

  \begin{align}
  \langle L_{j}^{A}|L_{k}^{A}\rangle & = |L_{j}^{A}\rangle^{\dagger}L_{k}^{A}\rangle  = \begin{bmatrix}A_{j,1}^{*} & A_{j,2}^{*} & \cdots & A_{j,n}^{*}\end{bmatrix}\begin{bmatrix}A_{k,1} \\ A_{k,2} \\ \vdots \\ A_{k,n}\end{bmatrix} \\
  & = A_{j,1}^{*}A_{k,1}+A_{j,2}^{*}A_{k,2}+\cdots+A_{j,n}^{*}A_{k,n} = \sum_{l=1}^{n}A_{k,l}(A^{\dagger})_{l,j} = (AA^{\dagger})_{k,j} = (\mathbb{I}_{n})_{k,j} \\ 
  & = \delta_{k,j}.
  \end{align}

  \textbf{Exercício:} Faça a verificação análoga para o conjunto de
  vetores coluna de uma matriz unitária.
\end{enumerate}

\textbf{Exercício:} Se lhes é fornecida uma matriz \(A\) cujos vetores
coluna formam uma base LI, qual procedimento podemos utilizar para obter
uma matriz unitária a partir de \(A\).


    % Add a bibliography block to the postdoc
    
    
    
    \end{document}
